{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Lung Segmentation Pipeline\n",
    "\n",
    "## Overview\n",
    "This notebook implements a complete segmentation pipeline for the Shenzhen chest X-ray dataset, distinguishing between background, left lung, and right lung using a UNet architecture with PyTorch.\n",
    "\n",
    "## Task Requirements\n",
    "- Load raw chest X-ray images and binary lung masks\n",
    "- Transform binary masks into three-class format (background, left lung, right lung)\n",
    "- Implement data pipeline with resizing, normalization, and augmentation\n",
    "- Create custom PyTorch Dataset and DataLoader\n",
    "- Train UNet model with configurable parameters\n",
    "- Log training/validation metrics and plot convergence curves\n",
    "- Evaluate on held-out test set\n",
    "- Visualize results with side-by-side comparisons\n",
    "- Save best model checkpoint\n",
    "- Provide inference functionality\n",
    "\n",
    "## Alternative Execution Methods\n",
    "**Recommended**: Use command line for production training:\n",
    "```bash\n",
    "uv run run.py mode=train\n",
    "uv run run.py mode=test\n",
    "```\n",
    "\n",
    "This notebook is for experimentation and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Dependencies\n",
    "\n",
    "Import all necessary modules for the segmentation pipeline:\n",
    "- **Configuration**: OmegaConf for YAML config management\n",
    "- **Dataset**: Custom ChestDataset with configurable transforms\n",
    "- **Transforms**: Image and mask preprocessing/augmentation\n",
    "- **Models**: UNet architecture with ResNet encoder\n",
    "- **Training**: Training loop, loss functions, optimizers\n",
    "- **Evaluation**: Testing, metrics, and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from chest_segment.dataset import (\n",
    "    ChestDataset,\n",
    "    ChestDatasetConfig,\n",
    "    get_dataloaders,\n",
    ")\n",
    "from chest_segment.transforms import (\n",
    "    get_mask_transforms,\n",
    "    get_image_transforms,\n",
    "    ChestMaskTransformsConfig,\n",
    "    ChestImageTransformsConfig,\n",
    "    get_all_transforms,\n",
    "    ChestAllTransformsConfig,\n",
    ")\n",
    "from chest_segment.models import get_model_from_config\n",
    "from chest_segment.utils import get_optimizer, get_loss, get_metrics, set_seed\n",
    "from chest_segment.train import train\n",
    "from chest_segment.test import test, evaluate, visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Setup\n",
    "\n",
    "### Configuration Section (as required by task)\n",
    "Load and display the complete configuration including:\n",
    "- **Paths**: Dataset locations and output directories\n",
    "- **Hyperparameters**: Learning rate, batch size, epochs\n",
    "- **Model Parameters**: UNet depth, encoder type, feature sizes\n",
    "- **Data Transforms**: Image size, augmentation settings\n",
    "- **Random Seeds**: For reproducibility\n",
    "\n",
    "**Design Choices Documented**:\n",
    "- UNet with ResNet18 encoder for good performance/speed balance\n",
    "- Combined Cross-Entropy + Dice Loss for multiclass segmentation\n",
    "- Adam optimizer with 1e-4 learning rate for stable training\n",
    "- Horizontal flip and rotation augmentations for generalization\n",
    "- 256x256 image size for memory efficiency while preserving detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(\"config/config.yaml\")\n",
    "set_seed(cfg.seed)\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Preparation\n",
    "\n",
    "### Data Pipeline Implementation\n",
    "Create the custom PyTorch Dataset that:\n",
    "- Loads raw chest X-ray images and binary lung masks\n",
    "- Transforms binary masks into three-class format (background=0, left_lung=1, right_lung=2)\n",
    "- Applies resizing, normalization, and augmentation\n",
    "- Splits data into train/validation/test sets\n",
    "\n",
    "**Data Pipeline Features**:\n",
    "- Automatic mask splitting: Binary masks → Left/Right lung separation\n",
    "- Configurable image resizing to 256x256\n",
    "- Normalization to [0,1] range\n",
    "- Train/Val/Test split with 80%/10%/10% ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = ChestDatasetConfig(**cfg.dataset)\n",
    "dataset = ChestDataset(dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Definition\n",
    "\n",
    "### UNet Architecture with Configurable Parameters\n",
    "Create the UNet model with:\n",
    "- **Encoder**: ResNet18 backbone (configurable)\n",
    "- **Decoder**: Symmetric decoder with skip connections\n",
    "- **Output**: 3-channel output for multiclass segmentation\n",
    "- **Configurable Depth**: Adjustable number of encoder/decoder levels\n",
    "- **Feature Map Sizes**: Configurable channel dimensions\n",
    "\n",
    "**Model Architecture Details**:\n",
    "- Uses segmentation-models-pytorch library for proven UNet implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_from_config(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Setup\n",
    "\n",
    "### Training Configuration\n",
    "Prepare all components for training:\n",
    "- **Data Transforms**: Apply training-specific augmentations\n",
    "- **DataLoaders**: Create train/validation loaders with proper batching\n",
    "- **Loss Function**: Combined Cross-Entropy + Dice Loss for multiclass segmentation\n",
    "- **Optimizer**: Adam with configurable learning rate\n",
    "- **Metrics**: Jaccard (IoU) for evaluation\n",
    "\n",
    "**Training Features**:\n",
    "- **Augmentation**: Horizontal flip (p=0.5), rotation (±10°, p=0.5)\n",
    "- **Loss Combination**: CE + 0.5×Dice for balanced optimization\n",
    "- **Batch Size**: 16 for memory efficiency\n",
    "- **Metrics Logging**: Jaccard score for each class\n",
    "- **Checkpointing**: Save best model based on validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_transforms(\n",
    "    image_transforms=get_image_transforms(\n",
    "        ChestImageTransformsConfig(**cfg.train.image_transforms)\n",
    "    )\n",
    "    if cfg.train.image_transforms\n",
    "    else None,\n",
    "    mask_transforms=get_mask_transforms(\n",
    "        ChestMaskTransformsConfig(**cfg.train.mask_transforms)\n",
    "    )\n",
    "    if cfg.train.mask_transforms\n",
    "    else None,\n",
    "    all_transforms=get_all_transforms(\n",
    "        ChestAllTransformsConfig(**cfg.train.all_transforms)\n",
    "    )\n",
    "    if cfg.train.all_transforms\n",
    "    else None,\n",
    ")\n",
    "train_loader, val_loader, test_loader = get_dataloaders(\n",
    "    dataset, dataset_config\n",
    ")\n",
    "\n",
    "criterion = get_loss(cfg)\n",
    "metrics = get_metrics(cfg)\n",
    "optimizer = get_optimizer(model, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "### Training Loop with Metrics Logging\n",
    "Execute the training process with:\n",
    "- **Epoch-wise Training**: Complete passes through training data\n",
    "- **Validation**: Evaluate on held-out validation set each epoch\n",
    "- **Metrics Logging**: Track training and validation metrics\n",
    "- **TensorBoard Integration**: Real-time training curves\n",
    "- **Checkpointing**: Save best model based on validation performance\n",
    "\n",
    "**Training Monitoring**:\n",
    "- Loss curves for training and validation\n",
    "- Jaccard (IoU) scores for each class\n",
    "- Learning rate scheduling (if configured)\n",
    "- Early stopping to prevent overfitting\n",
    "\n",
    "**Expected Convergence**:\n",
    "- Training loss should decrease steadily\n",
    "- Validation metrics should improve\n",
    "- Watch for overfitting (validation metrics plateau while training continues improving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    model, train_loader, val_loader, criterion, optimizer, metrics, cfg.train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Testing\n",
    "\n",
    "### Test Set Evaluation\n",
    "Evaluate the trained model on the held-out test set:\n",
    "- **Test Transforms**: Apply test-specific preprocessing (no augmentation)\n",
    "- **Metrics Calculation**: Compute final performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_transforms(\n",
    "    image_transforms=get_image_transforms(\n",
    "        ChestImageTransformsConfig(**cfg.test.image_transforms)\n",
    "        if cfg.test.image_transforms\n",
    "        else None\n",
    "    ),\n",
    "    mask_transforms=get_mask_transforms(\n",
    "        ChestMaskTransformsConfig(**cfg.test.mask_transforms)\n",
    "        if cfg.test.mask_transforms\n",
    "        else None\n",
    "    ),\n",
    "    all_transforms=get_all_transforms(\n",
    "        ChestAllTransformsConfig(**cfg.test.all_transforms)\n",
    "        if cfg.test.all_transforms\n",
    "        else None\n",
    "    ),\n",
    ")\n",
    "train_loader, val_loader, test_loader = get_dataloaders(\n",
    "    dataset, dataset_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_loader, criterion, metrics, cfg.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Inference (Task Requirement)\n",
    "\n",
    "### Inference Cell for New Images\n",
    "Load the saved checkpoint and run inference on new images:\n",
    "- **Checkpoint Loading**: Load best trained model\n",
    "- **New Image Processing**: Apply same preprocessing pipeline\n",
    "- **Prediction**: Generate segmentation mask\n",
    "- **Overlay Visualization**: Show segmentation on original X-ray\n",
    "\n",
    "**Inference Pipeline**:\n",
    "- Loads best model from checkpoints\n",
    "- Applies same transforms as testing\n",
    "- Generates multiclass predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset.from_split(split=\"test\", config=dataset.config)\n",
    "idxes = list(range(5))\n",
    "preds = evaluate(model, test_dataset, idxes=idxes, device=cfg.device)\n",
    "visualize(preds, test_dataset, idxes=idxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Generated Artifacts\n",
    "\n",
    "1. TensorBoard logs in `logs/` directory\n",
    "2. Model checkpoints in `checkpoints/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
